{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "XZ3kZj4Lw9lD"
            },
            "source": [
                "## Workspace setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 15061,
                    "status": "ok",
                    "timestamp": 1699476016513,
                    "user": {
                        "displayName": "Maciej Bajor",
                        "userId": "12724909867748285451"
                    },
                    "user_tz": -60
                },
                "id": "J_B21IVsgueS",
                "outputId": "99522e6e-7e21-4dc6-f347-f908eeac033c"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Mounted at /content/drive\n"
                    ]
                }
            ],
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 13673,
                    "status": "ok",
                    "timestamp": 1699476032047,
                    "user": {
                        "displayName": "Maciej Bajor",
                        "userId": "12724909867748285451"
                    },
                    "user_tz": -60
                },
                "id": "mhzkPMnplaAx",
                "outputId": "92bfd36e-f26b-438b-ea0d-bdaeb904c21c"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Collecting uproot\n",
                        "  Downloading uproot-5.1.2-py3-none-any.whl (342 kB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.7/342.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hCollecting awkward>=2.4.6 (from uproot)\n",
                        "  Downloading awkward-2.4.9-py3-none-any.whl (718 kB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.6/718.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from uproot) (1.23.5)\n",
                        "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from uproot) (23.2)\n",
                        "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from uproot) (4.5.0)\n",
                        "Collecting awkward-cpp==25 (from awkward>=2.4.6->uproot)\n",
                        "  Downloading awkward_cpp-25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from awkward>=2.4.6->uproot) (6.8.0)\n",
                        "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->awkward>=2.4.6->uproot) (3.17.0)\n",
                        "Installing collected packages: awkward-cpp, awkward, uproot\n",
                        "Successfully installed awkward-2.4.9 awkward-cpp-25 uproot-5.1.2\n"
                    ]
                }
            ],
            "source": [
                "!pip install uproot"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "eV5Sj4vAmH6W"
            },
            "outputs": [],
            "source": [
                "!cp drive/MyDrive/ZPS/WAWTPC/*.py /content"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "i8fj12dhw9lF",
                "outputId": "1791e02e-89ec-41f7-e22d-2bc62af70e7f",
                "tags": []
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-05-30 14:08:02.828531: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
                    ]
                }
            ],
            "source": [
                "from datetime import datetime\n",
                "import uproot\n",
                "import awkward as ak\n",
                "import tensorflow as tf\n",
                "import numpy as np\n",
                "import importlib\n",
                "from functools import partial\n",
                "\n",
                "from tensorflow.data import Dataset, TFRecordDataset\n",
                "from tensorflow.data.experimental import TFRecordWriter\n",
                "from tensorflow.train import BytesList, FloatList, Int64List\n",
                "from tensorflow.train import Example, Features, Feature"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "kpKA2_GQw9lG"
            },
            "source": [
                "## TFRecord creation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "6nn-szPjw9lG",
                "outputId": "4a2eb3f6-a4a0-432e-afe9-196c74057423",
                "tags": []
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-05-30 14:13:23.960551: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
                        "\t [[{{node Placeholder/_0}}]]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 1min 37s, sys: 24.7 s, total: 2min 2s\n",
                        "Wall time: 2min 1s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "import io_functions as io\n",
                "importlib.reload(io)\n",
                "\n",
                "dataPath = 'drive/MyDrive/ZPS/'\n",
                "train_files = [dataPath+'out_C_arr_1.root:TPCData']\n",
                "batchSize = 200\n",
                "\n",
                "datasetGenerator = partial(io.generator, files=train_files, batchSize=batchSize)\n",
                "\n",
                "train_dataset = tf.data.Dataset.from_generator(\n",
                "     datasetGenerator,\n",
                "     output_signature=(\n",
                "         tf.TensorSpec(shape=(batchSize,)+ io.projections.shape, dtype=tf.int32),\n",
                "         tf.TensorSpec(shape=(batchSize, 9), dtype=tf.float32)))\n",
                "\n",
                "\n",
                "for aBatch in train_dataset:\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "K8LVzZr2w9lH",
                "outputId": "094fcf25-557a-47aa-bd64-4a958a65602f",
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 2min 24s, sys: 663 ms, total: 2min 25s\n",
                        "Wall time: 2min 24s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "dataFile = \"out_C_arr_1.root\"\n",
                "treeName = \":TPCData\"\n",
                "inputObj = dataPath+dataFile+treeName\n",
                "batchSize = 1\n",
                "\n",
                "fields = [\n",
                "    #\"SimEvent/reactionType\",\n",
                "    \"SimEvent/tracks/tracks.startPos\",\n",
                "    \"SimEvent/tracks/tracks.stopPos\",\n",
                "    #\"SimEvent/tracks/tracks.prim.pID\",\n",
                "    #\"SimEvent/tracks/tracks.prim.fourMomentum\",\n",
                "    #\"Event/myChargeMap\",\n",
                "    \"Event/myChargeArray*\",\n",
                "    \"SimEvent/tracks/tracks.truncatedStartPosUVWT.*\",\n",
                "    \"SimEvent/tracks/tracks.truncatedStopPosUVWT.*\",\n",
                "]\n",
                "\n",
                "\n",
                "def generator(files):\n",
                "    for array in uproot.iterate(files, step_size=batchSize, filter_name=fields, library=\"ak\"):\n",
                "\n",
                "        fX = array['tracks.startPos']['fX'].to_numpy()\n",
                "        fY = array['tracks.startPos']['fY'].to_numpy()\n",
                "        fZ = array['tracks.startPos']['fZ'].to_numpy()\n",
                "        startPos = np.stack([fX, fY, fZ], axis=1)[:,:,[0]]\n",
                "\n",
                "        fX = array['tracks.stopPos']['fX'].to_numpy()\n",
                "        fY = array['tracks.stopPos']['fY'].to_numpy()\n",
                "        fZ = array['tracks.stopPos']['fZ'].to_numpy()\n",
                "        stopPos = np.stack([fX, fY, fZ], axis=1)\n",
                "\n",
                "        target = np.concatenate([startPos, stopPos], axis=2)\n",
                "\n",
                "        features = array[\"myChargeArray[3][3][256][512]\"].to_numpy()\n",
                "        features = np.sum(features, axis=2)\n",
                "        features = np.moveaxis(features, 1, -1)\n",
                "\n",
                "        yield features, target\n",
                "\n",
                "for item in generator(files=inputObj):\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "QEntYclvw9lH",
                "outputId": "af7e3417-e670-4491-c601-a4b17e18d2f1",
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 1min 50s, sys: 10.3 s, total: 2min\n",
                        "Wall time: 2min\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "import io_functions as io\n",
                "importlib.reload(io)\n",
                "\n",
                "for item in io.generator(files=inputObj):\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "vrcROfz7w9lI",
                "tags": []
            },
            "outputs": [],
            "source": [
                "\n",
                "\n",
                "\n",
                "\n",
                "def saveDatasetToTFRecord(dataset, fileName):\n",
                "    dataset = dataset.map(.io.serialize_tensor)\n",
                "    writer = tf.data.experimental.TFRecordWriter(fileName, compression_type=\"GZIP\")\n",
                "    writer.write(dataset)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "JigmyW1Gw9lI"
            },
            "outputs": [],
            "source": [
                "path_tf = 'startPos.tfrecord'\n",
                "item_of_TPCData_list = 'SimEvent/tracks/tracks.startPos'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "jtZLNSoRw9lJ"
            },
            "outputs": [],
            "source": [
                "path_tf = 'stopPos.tfrecord'\n",
                "item_of_TPCData_list = 'SimEvent/tracks/tracks.stopPos'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "_KQbKggpw9lJ"
            },
            "outputs": [],
            "source": [
                "def generate_tfrecord(path_tf, item_of_TPCData_list):\n",
                "    with tf.io.TFRecordWriter(path_tf) as file_writer:\n",
                "        for x in TPCData.iterate(item_of_TPCData_list, step_size=1):\n",
                "\n",
                "            record_bytes = tf.train.Example(features=tf.train.Features(feature={\n",
                "                \"fX\": tf.train.Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(x[item_of_TPCData_list]['fX']).numpy()])),\n",
                "                \"fY\": tf.train.Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(x[item_of_TPCData_list]['fY']).numpy()])),\n",
                "                \"fZ\": tf.train.Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(x[item_of_TPCData_list]['fZ']).numpy()])),\n",
                "\n",
                "\n",
                "            })).SerializeToString()\n",
                "            file_writer.write(record_bytes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "SNxceI2-w9lK"
            },
            "outputs": [],
            "source": [
                "generate_tfrecord(path_tf, item_of_TPCData_list)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "iuG2eVojw9lK"
            },
            "outputs": [],
            "source": [
                "list_of_tfrecord_files = ['stopPos.tfrecord', 'startPos.tfrecord']\n",
                "dataset = tf.data.TFRecordDataset(list_of_tfrecord_files)\n",
                "\n",
                "filename = 'root.tfrecord'\n",
                "writer = tf.data.experimental.TFRecordWriter(filename)\n",
                "writer.write(dataset)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "l4Eni6c9w9lL"
            },
            "outputs": [],
            "source": [
                "#train_dataset = tf.data.Dataset.from_generator(\n",
                "#     datasetGenerator,\n",
                "#     output_signature=(\n",
                "#         tf.TensorSpec(shape=(io.projections.shape), dtype=tf.float32),\n",
                "#         tf.TensorSpec(shape=(9), dtype=tf.float64)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "1x2528SXw9lL"
            },
            "outputs": [],
            "source": [
                "nStrips=256\n",
                "nTimeSlices = 512\n",
                "nProj = 3\n",
                "projections = np.zeros((nStrips,nTimeSlices, nProj))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "yu5zVLpIw9lM"
            },
            "outputs": [],
            "source": [
                "def generate_tfrecord_tfDataset(path_tf):\n",
                "    with tf.io.TFRecordWriter(path_tf) as file_writer:\n",
                "        for x in train_dataset:\n",
                "\n",
                "            record_bytes = tf.train.Example(features=tf.train.Features(feature={\n",
                "                \"projections\": tf.train.Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(x).numpy()]),\n",
                "                                         )\n",
                "\n",
                "\n",
                "            })).SerializeToString()\n",
                "            file_writer.write(record_bytes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "766ePbxgw9lM"
            },
            "outputs": [],
            "source": [
                "#generate_tfrecord_tfDataset('projections_test.tfrecord')"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}